# 부스팅 (Boosting):

• 정의: 가중치가 부여된 훈련 세트에서 순차적으로 모델을 훈련시키며 이전 모델의 오류를 보정하는 방법.

• 과정:

• 순차적으로 모델을 훈련하면서 각 모델은 이전 모델의 오류를 보정.

• 오분류된 인스턴스에 높은 가중치를 할당하여 다음 모델에서 우선 순위 부여.

• 모델을 결합할 때는 약한 모델에 낮은 가중치를 할당.

• 알고리즘: 주로 XGBoost, CatBoost, AdaBoost와 같은 알고리즘 사용.

• 목적: 약한 학습기의 성능을 향상시켜 정확도를 높임.



# 배깅(Bagging)

## 1. 배깅의 정의
**배깅(Bagging)** 또는 **부트스트랩 집계**는 부트스트래핑(bootstrapping)과 집계(aggregation)의 이점을 결합하여 안정된 모델을 얻고 기계 학습 모델의 예측 성능을 향상시키는 앙상블 학습 기술

### 1.1. 정확한 의미
- 부트스트래핑(복원 추출)을 사용하여 데이터셋에서 동일한 크기의 하위 집합을 샘플링
- 샘플링된 하위 집합을 사용하여 여러 약한 모델들을 독립적으로 훈련 (약한 모델: 예측 정확도가 낮은 모델)
- 약한 모델들의 예측을 집계하여 강한 모델을 얻음

### 1.2. 과정
1. 복원 샘플링을 통한 동일 크기의 부분집합 샘플링
2. 각 부분집합에 대해 독립적이고 병렬로 약한 모델을 훈련
3. 각 약한 모델의 결과를 평균이나 투표를 통해 결합하여 최종 결과 획득
4. 회귀 작업의 경우 결과를 평균화하고, 분류 작업의 경우 다수결 클래스를 선택하여 결과를 집계

### 1.3. 목적
- 데이터셋의 분산을 감소시켜 모델이 특정 샘플에 영향을 받지 않고 견고하게 만듦

### 1.4. 사용처
- 주로 의사 결정 트리와 랜덤 포레스트와 같은 트리 기반의 기계 학습 모델에 적용

## 2. 배깅의 장단점

### 2.1. 장점
- 모델의 분산을 감소시켜 안정성을 향상
- 특정 샘플의 영향을 줄이므로 과적합을 방지

### 2.2. 단점
- 계산 비용이 증가
- 모델 해석이 어려워질 수 있음

배깅은 모델의 예측 성능을 향상시키는 데 널리 사용되지만, 계산 비용 및 모델 해석의 어려움을 고려해야 함




# 스태킹(Stacking)

## 1. 정의
**스태킹(Stacking)**은 기계 학습에서 강력한 앙상블 학습 전략으로, 여러 기본 모델의 예측을 결합하여 더 나은 성능의 최종 예측을 얻는 기술로 알려져 있음. 또한 **스태킹 앙상블** 또는 **적층 일반화**로도 불림

### 1.1. 스태킹의 정확한 의미
- 여러 기본 모델(첫 번째 수준 모델 또는 기본 학습자라고도 함)의 예측을 결합하여 최종 예측을 얻는 기계 학습 전략
- 동일한 훈련 데이터 세트에서 여러 기본 모델을 훈련시키고, 그들의 예측을 상위 수준 모델(메타 모델 또는 두 번째 수준 모델이라고도 함)에 입력하여 최종 예측을 수행
- 스태킹의 주요 아이디어는 서로 다른 기본 모델의 예측을 결합하여 단일 모델을 사용하는 것보다 더 탁월한 예측 성능을 얻음

### 1.2. 스태킹의 과정
1. **데이터 분할:**
   - 훈련 데이터를 두 부분으로 나눔
   
2. **기본 모델 훈련:**
   - 훈련 데이터에서 여러 기본 모델을 훈련
   
3. **검증 데이터에서 예측:**
   - 기본 모델들을 사용하여 보류 중인 검증 데이터에 대한 예측을 수행
   
4. **메타 모델 훈련:**
   - 메타 모델 또는 두 번째 수준 모델을 보류 중인 검증 데이터의 기본 모델 예측을 입력 특성으로 사용하여 훈련
   
5. **새로운 데이터에 대한 예측:**
   - 새로운 데이터에 대한 예측을 수행하기 위해 메타 모델을 사용
   
6. **성능 평가:**
   - 훈련 중 사용되지 않은 별도의 테스트 데이터셋에서 스태킹 모델의 성능을 평가

### 1.3. 스태킹의 목표
		- **스태킹의 목표**는 다양한 기본 모델의 강점을 결합하여 메타 모델에 입력하여 그들의 예측을 가중치를 학습하고 결합하여 최종 예측을 생성하는 것
		- 이로 인해 종종 단일 모델만 사용하는 것보다 높은 성능을 얻을 수 있음

## 2. 스태킹의 장점
- **향상된 예측 성능:** 여러 기본 모델의 결과를 결합하여 최종 예측을 얻음으로써 최종 예측의 편향과 분산을 줄일 수 있어 예측 성능이 향상
- **모델 다양성:** 다양한 기본 모델을 사용함으로써 다양성을 확보하여 오버피팅의 위험을 감소시키고 다양한 유형의 데이터에 대해 견고한 스태킹 앙상블을 만듦
- **유연성:** 스태킹은 분류, 회귀, 시계열 예측과 같은 다양한 기계 학습 문제를 해결하는 데 사용될 수 있는 다재다능한 전략
- **해석 가능성:** 각 기본 모델 및 메타 모델의 중요성 및 예측에 대한 이해를 제공하여 상대적인 중요성 및 해석 가능성을 확인할 수 있음

## 3. 스태킹의 최적화를 위한 모범 사례
- **모델 다양성:** 다양한 기본 모델을 사용하여 다양성을 확보하는 것이 중요합니다. 비슷한 모델이나 유사한 하이퍼파라미터 설정을 사용하는 것을 피하여 성능 향상을 이끌어내는 것이 중요
- **데이터 누수 방지:** 스태킹에서는 데이터 누수에 주의해야 합니다. 검증 또는 테스트 세트에서의 정보가 기본 모델 또는 메타 모델의 훈련 중에 사용되지 않도록 주의
- **성능 평가:** 스태킹 앙상블의 성능을 평가할 때는 적절한 평가 지표와 교차 검증 또는 보류 중인 검증 기술을 사용해야 함
- **메타 모델 선택:** 문제에 가장 적합한 메타 모델을 결정하기 위해 여러 메타 모델을 실험적으로 살펴야 함
- **하이퍼파라미터 조정:** 기본 및 메타 모델의 하이퍼파라미터를 최적화하여 스태킹 앙상블의 성능에 큰 영향을 줄 수 있음
- **앙상블 크기:** 많은 기본 모델을 사용하면 과적합 및 계산 복잡성이 증가할 수 있습니다. 적절한 앙상블 크기를 찾기 위해 여러 크기를 실험적으로 시도해야 함
